{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from transformers import AutoModelForTokenClassification,AutoTokenizer, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/Phagedepo.Dataset.21032024.tsv \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "path_tmp = f\"{path_work}/tmp\"\n",
    "os.makedirs(path_tmp, exist_ok=True)\n",
    "\n",
    "df_depo = pd.read_csv(f\"{path_work}/Phagedepo.Dataset.21032024.tsv\" , sep = \"\\t\" , header = 0)\n",
    "df_depo = df_depo[df_depo[\"Fold\"].isin([\"Negative\", \"right-handed beta-helix\", \"6-bladed beta-propeller\", \"triple-helix\"])]\n",
    "df_depo = df_depo.drop_duplicates(subset = [\"Full_seq\"], keep = \"first\")\n",
    "df_depo.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make the cd hit input/outputs : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thresholds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m seq \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dico_seq_id : \n\u001b[1;32m      6\u001b[0m             dico_seq_id[seq] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c_value \u001b[38;5;129;01min\u001b[39;00m thresholds :\n\u001b[1;32m      9\u001b[0m     make_cdhit_cluster(c_value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'thresholds' is not defined"
     ]
    }
   ],
   "source": [
    "dico_seq_id = {}\n",
    "with open(f\"{path_tmp}/training_sequences.fasta\", \"w\") as outfile :\n",
    "    for index, seq in enumerate(df_depo[\"Full_seq\"].tolist()) : \n",
    "        outfile.write(f\">{index}\\n{seq}\\n\")\n",
    "        if seq not in dico_seq_id : \n",
    "            dico_seq_id[seq] = index\n",
    "\n",
    "for c_value in thresholds :\n",
    "    make_cdhit_cluster(c_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.65, 0.7, 0.75, 0.8, 0.85]\n",
    "\n",
    "def make_cdhit_cluster(threshold) :\n",
    "    cdhit_command = f\"cd-hit -i {path_tmp}/training_sequences.fasta -o {path_tmp}/{threshold}.out -c {threshold} -G 0 -aL 0.8\"\n",
    "    cdhit_process = subprocess.Popen(cdhit_command, shell =True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) \n",
    "    scan_out, scan_err = cdhit_process.communicate()\n",
    "    print(scan_out, scan_err)\n",
    "\n",
    "\n",
    "def make_cluster_dico(cdhit_out) :\n",
    "    import json\n",
    "    dico_cluster = {}\n",
    "    threshold = cdhit_out.split(\"/\")[-1].split(\".out\")[0]\n",
    "    cluster_file = f\"{cdhit_out}.clstr\"\n",
    "    cluster_out = open(cluster_file).read().split(\">Cluster\")\n",
    "    for index,cluster in enumerate(cluster_out[1:]) :\n",
    "        tmp_dpo = []\n",
    "        #id_cluster = f\"Dpo_cdhit_{index}\"\n",
    "        id_cluster = index\n",
    "        for _,line in enumerate(cluster.split(\"\\n\")[1:-1]) :\n",
    "            dpo = line.split(\">\")[1].split(\".\")[0]\n",
    "            tmp_dpo.append(dpo)\n",
    "        dico_cluster[id_cluster] = tmp_dpo\n",
    "    with open(f\"{path_tmp}/dico_cluster.cdhit__{threshold}.json\", \"w\") as outfile:\n",
    "        json.dump(dico_cluster, outfile)\n",
    "    return dico_cluster , threshold\n",
    "\n",
    "\n",
    "def reverse_dico(dico) : \n",
    "    r_dico = {}\n",
    "    for key,values in dico.items() :\n",
    "        for _,id in enumerate(values) : \n",
    "            r_dico[id] = key\n",
    "    return r_dico\n",
    "\n",
    "\n",
    "def make_list_group(list_seq, r_dico, id_dico) :\n",
    "    list_group = []\n",
    "    for _,seq in enumerate(list_seq) :\n",
    "        idd_seq = str(id_dico[seq])\n",
    "        list_group.append(r_dico[idd_seq])\n",
    "    return list_group\n",
    "\n",
    "\n",
    "def cvalue_to_list_group(threshold, df_depo) :\n",
    "    dico_cluster, _ = make_cluster_dico(f\"{path_tmp}/{threshold}.out\")\n",
    "    r_dico_cluster = reverse_dico(dico_cluster)\n",
    "    list_groups = make_list_group(df_depo[\"Full_seq\"].tolist(), r_dico_cluster, dico_seq_id)\n",
    "    return list_groups\n",
    "\n",
    "\n",
    "def get_labels(tuple_data ) :\n",
    "    dico_labels = {\"Negative\" : 0,\n",
    "                   \"right-handed beta-helix\" : 1,\n",
    "                   \"6-bladed beta-propeller\" : 2, \n",
    "                   \"triple-helix\" : 3}\n",
    "    labels_df = []\n",
    "    for _,row in enumerate(tuple_data) :\n",
    "        info = row[1]\n",
    "        seq_length = len(row[0])\n",
    "        fold = row[2]\n",
    "        label = dico_labels[fold]\n",
    "        if info == \"Negative\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info == \"full_protein\" or info == \"full\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info.count(\":\") > 0 : \n",
    "            start = int(info.split(\":\")[0])\n",
    "            end = int(info.split(\":\")[1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "        else :\n",
    "            start = int(info.split(\"_\")[-2])\n",
    "            end = int(info.split(\"_\")[-1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "    return labels_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "\n",
    "list_test_1 = cvalue_to_list_group(threshold, df_depo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_token_class = GroupShuffleSplit(n_splits=1, train_size=0.7, test_size = 0.3, random_state=243)\n",
    "gss_seq_class = GroupShuffleSplit(n_splits=1, train_size=0.66, test_size = 0.34, random_state=243)\n",
    "\n",
    "# First split :\n",
    "train_token_classification_indices = []\n",
    "Other_indices = []\n",
    "for i, (train_index, test_index) in enumerate(gss_token_class.split(df_depo[\"Full_seq\"], df_depo[\"Fold\"], list_test_1)):\n",
    "    train_token_classification_indices.append(train_index)\n",
    "    Other_indices.append(test_index)\n",
    "\n",
    "train_tok_seq = df_depo[\"Full_seq\"][train_token_classification_indices[0]]\n",
    "train_tok_boundaries = df_depo[\"Boundaries\"][train_token_classification_indices[0]]\n",
    "train_tok_fold = df_depo[\"Fold\"][train_token_classification_indices[0]]\n",
    "\n",
    "training_data_token_class = tuple(zip(train_tok_seq, train_tok_boundaries, train_tok_fold))\n",
    "training_data_tok_labels = get_labels(training_data_token_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Seq_ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Full_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MF417929_00041</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MNTPQPIQFDLMNPRQHGRILFAMGMSVSEIAKQIDEKRATVESWK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MH616963_00015</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MAKDNYPFLDYINEDKSHYKTAASAGYKDDENLFLIGESGGFLMNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>LR797314_00041</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MDHITEEMLAKFRDEHLYKHQRIIYDAGQDLLTCRNRIILKPRQVG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>AP013549_00033</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MAEYPTPVQMQILDYLENGPKRRVIAAFRGCGKSTLSAMYILWRLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>AP013546_00036</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MNELWEPLPPALRDSFPNFACYLLRELRLADTPTRQQISVCDWMQN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2201</td>\n",
       "      <td>2201</td>\n",
       "      <td>PL16__55</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>137:347</td>\n",
       "      <td>MSKEVASARIQHRGMTTQGWESSPDILMEREIGIDMTTGYPKVGDG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2208</td>\n",
       "      <td>2208</td>\n",
       "      <td>PL16__33</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>0:210</td>\n",
       "      <td>MSLAGGIVTGQLRLKPNSGIEKSSSTGGAINIDMSKSKGAAMVMYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2214</td>\n",
       "      <td>2214</td>\n",
       "      <td>PL16__153</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>142:343</td>\n",
       "      <td>MSKEVASARIQHRGMTKQEWESSSDILMEREIGIDMTTGYPKVGDG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2216</td>\n",
       "      <td>2216</td>\n",
       "      <td>PL16__58</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>103:301</td>\n",
       "      <td>MTETIPLRVQFKRMTAEEWARSDVILLESEIGFETDTGYAKFGDGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2233</td>\n",
       "      <td>2233</td>\n",
       "      <td>PL16__66</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>102:304</td>\n",
       "      <td>MTETIPLRVQFKRMTAEEWARSDVILLEGEIGFETDTGYAKFGDGK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index          Seq_ID          Fold    Prob Boundaries  \\\n",
       "0          1      1  MF417929_00041      Negative  manual   Negative   \n",
       "1          2      2  MH616963_00015      Negative  manual   Negative   \n",
       "2          8      8  LR797314_00041      Negative  manual   Negative   \n",
       "3         10     10  AP013549_00033      Negative  manual   Negative   \n",
       "4         13     13  AP013546_00036      Negative  manual   Negative   \n",
       "..       ...    ...             ...           ...     ...        ...   \n",
       "666     2201   2201        PL16__55  triple-helix  manual    137:347   \n",
       "667     2208   2208        PL16__33  triple-helix  manual      0:210   \n",
       "668     2214   2214       PL16__153  triple-helix  manual    142:343   \n",
       "669     2216   2216        PL16__58  triple-helix  manual    103:301   \n",
       "670     2233   2233        PL16__66  triple-helix  manual    102:304   \n",
       "\n",
       "                                              Full_seq  \n",
       "0    MNTPQPIQFDLMNPRQHGRILFAMGMSVSEIAKQIDEKRATVESWK...  \n",
       "1    MAKDNYPFLDYINEDKSHYKTAASAGYKDDENLFLIGESGGFLMNI...  \n",
       "2    MDHITEEMLAKFRDEHLYKHQRIIYDAGQDLLTCRNRIILKPRQVG...  \n",
       "3    MAEYPTPVQMQILDYLENGPKRRVIAAFRGCGKSTLSAMYILWRLA...  \n",
       "4    MNELWEPLPPALRDSFPNFACYLLRELRLADTPTRQQISVCDWMQN...  \n",
       "..                                                 ...  \n",
       "666  MSKEVASARIQHRGMTTQGWESSPDILMEREIGIDMTTGYPKVGDG...  \n",
       "667  MSLAGGIVTGQLRLKPNSGIEKSSSTGGAINIDMSKSKGAAMVMYT...  \n",
       "668  MSKEVASARIQHRGMTKQEWESSSDILMEREIGIDMTTGYPKVGDG...  \n",
       "669  MTETIPLRVQFKRMTAEEWARSDVILLESEIGFETDTGYAKFGDGK...  \n",
       "670  MTETIPLRVQFKRMTAEEWARSDVILLEGEIGFETDTGYAKFGDGK...  \n",
       "\n",
       "[671 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intermediate DF : \n",
    "df_depo_s2 = df_depo[df_depo.index.isin(Other_indices[0])]\n",
    "df_depo_s2.reset_index(inplace = True)\n",
    "df_depo_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split : \n",
    "list_test_2 = cvalue_to_list_group(threshold,df_depo_s2)\n",
    "train_seq_classifiaction_indices = []\n",
    "eval_data_indices = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gss_seq_class.split(df_depo_s2[\"Full_seq\"], df_depo_s2[\"Fold\"], list_test_2)):\n",
    "    train_seq_classifiaction_indices.append(train_index)\n",
    "    eval_data_indices.append(test_index)\n",
    "\n",
    "train_seq_seq = df_depo_s2[\"Full_seq\"][train_seq_classifiaction_indices[0]]\n",
    "train_seq_boundaries = df_depo_s2[\"Boundaries\"][train_seq_classifiaction_indices[0]]\n",
    "train_seq_fold = df_depo_s2[\"Fold\"][train_seq_classifiaction_indices[0]]\n",
    "\n",
    "# Sequence classification data :\n",
    "training_data_seq_class = tuple(zip(train_seq_seq, train_seq_boundaries, train_seq_fold))\n",
    "training_data_seq_labels = get_labels(training_data_seq_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ealuation data :\n",
    "eval_seq = df_depo_s2[\"Full_seq\"][eval_data_indices[0]]\n",
    "eval_seq_boundaries = df_depo_s2[\"Boundaries\"][eval_data_indices[0]]\n",
    "eval_seq_fold = df_depo_s2[\"Fold\"][eval_data_indices[0]]\n",
    "\n",
    "eval_data_token_class = tuple(zip(eval_seq, eval_seq_boundaries, eval_seq_fold))\n",
    "eval_data_token_labels = get_labels(eval_data_token_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'Negative': 966,\n",
       "          'right-handed beta-helix': 442,\n",
       "          'triple-helix': 119,\n",
       "          '6-bladed beta-propeller': 54}),\n",
       " Counter({'Negative': 286,\n",
       "          'right-handed beta-helix': 105,\n",
       "          '6-bladed beta-propeller': 34,\n",
       "          'triple-helix': 17}),\n",
       " Counter({'Negative': 157,\n",
       "          'right-handed beta-helix': 55,\n",
       "          'triple-helix': 9,\n",
       "          '6-bladed beta-propeller': 8}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_tok_fold), Counter(train_seq_fold), Counter(eval_seq_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581, 442, 229)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok_fold), len(train_seq_fold), len(eval_seq_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_data_token_class = tuple(zip(eval_seq, eval_seq_boundaries, eval_seq_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "> Prepare the labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# II. Fine-tuning ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split :\n",
    "train_tok_seq = df_depo[\"Full_seq\"][train_token_classification_indices[0]]\n",
    "train_tok_boundaries = df_depo[\"Boundaries\"][train_token_classification_indices[0]]\n",
    "train_tok_fold = df_depo[\"Fold\"][train_token_classification_indices[0]]\n",
    "\n",
    "training_data_token_class = tuple(zip(train_tok_seq, train_tok_boundaries, train_tok_fold))\n",
    "training_data_tok_labels = get_labels(training_data_token_class)\n",
    "\n",
    "# Ealuation data :\n",
    "eval_seq = df_depo_s2[\"Full_seq\"][eval_data_indices[0]]\n",
    "eval_seq_boundaries = df_depo_s2[\"Boundaries\"][eval_data_indices[0]]\n",
    "eval_seq_fold = df_depo_s2[\"Fold\"][eval_data_indices[0]]\n",
    "\n",
    "eval_data_token_class = tuple(zip(eval_seq, eval_seq_boundaries, eval_seq_fold))\n",
    "eval_data_token_labels = get_labels(eval_data_token_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Define the model :\n",
    "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\"\n",
    "#model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"\n",
    "#model_checkpoint = \"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_tokenized = tokenizer(list(train_tok_seq))\n",
    "test_tokenized = tokenizer(list(eval_seq))\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", training_data_tok_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", eval_data_token_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForTokenClassification: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_labels = 4\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-depolymerase.0407.3_labels\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir='./logs',\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/concha-eloko/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 786\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 1.96 GiB total capacity; 1.24 GiB already allocated; 66.38 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15413/2688807664.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         )\n\u001b[0;32m-> 1500\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1501\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 1.96 GiB total capacity; 1.24 GiB already allocated; 66.38 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=FT_model\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=50gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=FT_model%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/fine_tune.esm2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# III. Testing the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model :\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/ \n",
    "\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb/script_files/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from collections import Counter\n",
    "import torch\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "#path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /media/concha-eloko/Linux/depolymerase_building/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels/checkpoint-550/ were not used when initializing EsmForTokenClassification: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForTokenClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=480, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = f\"{path_work}/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels/checkpoint-550/\"\n",
    "#model_path = \"/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase/checkpoint-198\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 370, 1: 249}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode input text\n",
    "input_text = \"MTVKISGILKDALARPLANVAIRFLSLKTSSNIVIGVDTDFRTANDGSYDIDVVSGTYGVLMNFGSYEKIGEINVYNDSLPGTLEDFLTIPGIEEITPEILAQVIQARNNAVNAANNAASDATTIINEQLQNQKNEFDQFLLSSGYVFLGDYEDGPFQFSVRNQYIRYSNQYYRLDAATDVGFTTTGTDATSFASDVTHFVLMDGDTLRQNLGSSDGTSWVAKLGNKPLVAISYYKNQGLSDQDAVQAAFNESSNILIDHDIALTDYITFDRSEECYVYRKPGVTITGHGYLPKLRTNPAHVVETAIRHSKTSDRGGSYDRTYSHQSLAAEMVVHDVLSTDPGQENFVALYSGIESFNCQKQRMWAFNTVTSAHNLKTGDEIYGCEIDMNVDGTLDGGGQFVGVYIAGIGDVRTCANADGIRVQRLRDGVYKWQYGLRIFDSMTGINITDASTYSIFASGSAPIVRRKTTQDGGWSYTHSLSASSVKWGVDDYGDTYSRRLYLGTGDGKSKNRVNLDGGVSYYTTNAAVAWGSIAANAYVDKDITTLVGVSIADWTNYTIDVTPIGYAGAMPVVAVQAYINSTKTQAYVRIINISGAPLSSCNVGLNIKVSGHSATN\"  # Replace this with your input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt', truncation= True)\n",
    "\n",
    "# Get token classifications\n",
    "with torch.no_grad() :\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# The model returns logits which can be turned into probabilities using softmax\n",
    "import torch\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# the order of labels in model.config.id2label should match the order of probabilities in probs\n",
    "labels = model.config.id2label\n",
    "\n",
    "tokens = []\n",
    "for token_id, token_probs in zip(input_ids[0], probs[0]):\n",
    "    top_label_id = token_probs.argmax().item()\n",
    "    tokens.append(int(labels[top_label_id].split(\"_\")[1]))\n",
    "    #print(f\"{tokenizer.decode([token_id])}: {labels[top_label_id]}\")\n",
    "    \n",
    "\"\"\"with open(f\"{path_work}/output.token.txt\", \"w\") as outfile :\n",
    "    outfile.write(str(tokens))\"\"\"\n",
    "dict(Counter(tokens))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tokens = np.array(tokens)  # convert your list to numpy array for convenience\n",
    "\n",
    "# create your plot\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot data\n",
    "for i in range(len(tokens) - 1):\n",
    "    if tokens[i] == 0:\n",
    "        color = 'black'\n",
    "    elif tokens[i] == 1:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        #tokens[i] == 1\n",
    "    plt.plot([i, i+1], [tokens[i], tokens[i+1]], color=color, marker='o')\n",
    "\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Label')\n",
    "plt.title('Label for each token')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.yticks(np.arange(2), ['0', '1'])  \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
