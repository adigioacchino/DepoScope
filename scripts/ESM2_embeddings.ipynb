{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL : generate ESM-2 embeddings for each proteins \n",
    "### I. Generate the sequence file\n",
    "### II. The embedding script\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the sequence idex file :\n",
    "import os \n",
    "from Bio import SeqIO\n",
    "import pandas as pd \n",
    "\n",
    "path_millard = \"/home/conchae/ML_depolymerase/get_candidates/millard\"\n",
    "\n",
    "data = {}\n",
    "for rec in SeqIO.parse(f\"{path_millard}/millard_depo.v2.fasta\" , \"fasta\") :\n",
    "    if rec.seq not in data :\n",
    "        data[rec.seq] = [rec.id.split(\"__\")[0]]\n",
    "    else :\n",
    "        data[rec.seq].append(rec.id.split(\"__\")[0])\n",
    "        \n",
    "with open(f\"{path_millard}/df_sequences.index.v2.csv\" ,\"w\") as outfile :\n",
    "    for index_seq, seq in enumerate(list(data.keys())) :\n",
    "        for prot in data[seq] :\n",
    "            outfile.write(f\"{index_seq}\\t{prot}\\t{seq}\\n\")\n",
    "        \n",
    "df = pd.read_csv(f\"{path_millard}/df_sequences.index.v2.csv\", sep=\"\\t\", names = [\"index\",\"id\",\"sequence\"])       \n",
    "df = df.drop_duplicates(subset=[\"index\"], keep=\"first\")\n",
    "df.to_csv(f\"{path_millard}/df_sequences.index.clean.v2.csv\", sep=\"\\t\", columns = [\"index\",\"sequence\"], index=False)\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{path_millard}/df_sequences.index.clean.v2.csv\", sep=\"\\t\")\n",
    "with open(f\"{path_millard}/millard_depo.indexed.v2.fasta\" , \"w\") as outfile :\n",
    "    dico_interest = df.to_dict(\"records\")\n",
    "    for row in dico_interest :\n",
    "        outfile.write(f\">{row['index']}\\n{row['sequence']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "II. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model, alphabet = esm.pretrained(esm2_t33_650M_UR50D())\n",
    "\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "df = pd.read_csv(f\"{path_millard}/df_sequences.index.clean.v2.csv\", sep=\"\\t\", names = [\"index\",\"sequence\"])       \n",
    "data = df.to_records(index=False)[1:]\n",
    "\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "# Extract per-residue representations (on CPU)\n",
    "with torch.no_grad():\n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]\n",
    "\n",
    "# Generate per-sequence representations via averaging\n",
    "# NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "sequence_representations = []\n",
    "for i, tokens_len in enumerate(batch_lens):\n",
    "    sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
    "\n",
    "# Look at the unsupervised self-attention map contact predictions\n",
    "import matplotlib.pyplot as plt\n",
    "for (_, seq), tokens_len, attention_contacts in zip(data, batch_lens, results[\"contacts\"]):\n",
    "    plt.matshow(attention_contacts[: tokens_len, : tokens_len])\n",
    "    plt.title(seq)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "0    Spark  20000   30days      1000\n",
      "1  PySpark  25000   40days      2300\n",
      "2   Python  22000   35days      1200\n",
      "3   pandas  30000   50days      2000\n",
      "4   Python  22000   40days      2300\n",
      "5    Spark  20000   30days      1000\n",
      "6   pandas  30000   50days      2000\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=ESM_2__\n",
    "#SBATCH --qos=long\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=50 \n",
    "#SBATCH --mem=200gb \n",
    "#SBATCH --time=10-00:00:00 \n",
    "#SBATCH --output=ESM_2__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/software/esm/scripts/extract.py \\\n",
    "esm2_t33_650M_UR50D \\\n",
    "/home/conchae/ML_depolymerase/get_candidates/millard/millard_depo.indexed.v2.fasta \\\n",
    "/home/conchae/ML_depolymerase/get_candidates/millard/millard_depo.indexed.v2.esm2_out \\\n",
    "--repr_layers 0 32 33 \\\n",
    "--include mean per_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory some_proteins_emb_esm2/ now contains one .pt file per FASTA sequence; use torch.load() to load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "path_millard = \"/home/conchae/ML_depolymerase/get_candidates/millard/millard_depo.indexed.v2.esm2_out\"\n",
    "\n",
    "embeddings_esm = {}\n",
    "for file in os.listdir(path_millard) :\n",
    "    index = file.split(\".pt\")[0]\n",
    "    embb = torch.load(f\"{path_millard}/{file}\")[\"mean_representations\"][33].tolist()\n",
    "    embeddings_esm[index] = embb\n",
    "    \n",
    "with open(f\"/home/conchae/ML_depolymerase/get_candidates/millard/embeddings.proteins.v2.csv\" , \"w\") as outfile :\n",
    "    for index in embeddings_esm :\n",
    "        outfile.write(f\"{index},\")\n",
    "        for _,  emb in enumerate(embeddings_esm[index]) :\n",
    "            outfile.write(f\"{emb},\")\n",
    "        outfile.write(\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh conchae@garnatxa.srv.cpd:/home/conchae/ML_depolymerase/get_candidates/millard/millard_depo.indexed.v2.fasta /media/concha-eloko/Linux/depolymerase_building\n",
    "rsync -avzhe ssh conchae@garnatxa.srv.cpd:/home/conchae/ML_depolymerase/get_candidates/millard/embeddings.proteins.v2.csv /media/concha-eloko/Linux/depolymerase_building\n",
    "rsync -avzhe ssh conchae@garnatxa.srv.cpd:/home/conchae/ML_depolymerase/get_candidates/millard/df_sequences.index.v2.csv /media/concha-eloko/Linux/depolymerase_building\n",
    "rsync -avzhe ssh conchae@garnatxa.srv.cpd:/home/conchae/ML_depolymerase/get_candidates/millard/proteinID_annotation.v2.json /media/concha-eloko/Linux/depolymerase_building\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
