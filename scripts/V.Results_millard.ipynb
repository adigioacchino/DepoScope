{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the results of the Millard DB\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "#import pprint\n",
    "import json \n",
    "#pp = pprint.PrettyPrinter(width = 150)\n",
    "# Generate a list of path of filtered MSA \n",
    "path_proteins = \"/home/conchae/ML_depolymerase/get_candidates/millard\"\n",
    "path_out = \"/home/conchae/ML_depolymerase/get_candidates/millard/DBsuite_depo3\"\n",
    "path_tab = [f\"{path_out}/{file}\" for file in os.listdir(f\"{path_out}\") if file[-3:]==\"tab\"]\n",
    "\n",
    "out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"query_start\",\"query_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "\n",
    "def scan_tab(query_list) :\n",
    "    scores = []\n",
    "    dico_ipr = {}\n",
    "    depolymerase_dico = {}\n",
    "    for query in query_list:\n",
    "        out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"query_start\",\"query_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "        df_tab = pd.read_csv(f\"{query}\", sep=\"\\t\", names= out_names)\n",
    "        dico_tab = df_tab.to_dict(\"records\")\n",
    "        for row in dico_tab :\n",
    "            align_cols = int(row[\"query_stop\"]) - int(row[\"query_start\"])\n",
    "            if align_cols > 30 and row[\"score\"] > 20 :\n",
    "                ipr = row[\"target\"].split(\".ready\")[0]\n",
    "                prot = row[\"query\"]\n",
    "                scores.append(row[\"score\"])\n",
    "                if prot not in depolymerase_dico :\n",
    "                    positive_out = []\n",
    "                    positive_out.append(f\"{ipr}__{row['score']}\")\n",
    "                    depolymerase_dico[prot] = positive_out\n",
    "                else :\n",
    "                    depolymerase_dico[prot].append(f\"{ipr}__{row['score']}\")\n",
    "                if ipr not in dico_ipr :\n",
    "                    sco = []\n",
    "                    sco.append(row[\"score\"])\n",
    "                    dico_ipr[ipr]=sco\n",
    "                else :\n",
    "                    dico_ipr[ipr].append(row[\"score\"])\n",
    "    dico_count = {ipr : len(dico_ipr[ipr]) for ipr in dico_ipr}\n",
    "    return scores, dico_count, dico_ipr, depolymerase_dico\n",
    "\n",
    "scores_out , dico_count_out, dico_ipr_out, depolymerase_dico_out = scan_tab(path_tab)\n",
    "\n",
    "with open(f\"{path_proteins}/dico_ipr_out.v3.json\", \"w\") as outfile:\n",
    "    json.dump(dico_ipr_out, outfile)\n",
    "with open(f\"{path_proteins}/dico_ipr_count.v3.json\", \"w\") as outfile:\n",
    "    json.dump(dico_count_out, outfile)    \n",
    "with open(f\"{path_proteins}/dbsuite_results.v3.json\", \"w\") as outfile:\n",
    "    json.dump(depolymerase_dico_out, outfile) \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "\n",
    "#pp = pprint.PrettyPrinter(width = 150)\n",
    "# Generate a list of path of filtered MSA \n",
    "path_proteins = \"/home/conchae/ML_depolymerase/get_candidates/millard\"\n",
    "path_mill_db = \"/home/conchae/databases/Millard_jan_2023/5Jan2023_vConTACT2_proteins.faa\"\n",
    "\n",
    "dico_res = json.load(open(f\"{path_proteins}/dbsuite_results.v3.json\"))\n",
    "dico_count = json.load(open(f\"{path_proteins}/dico_ipr_count.v3.json\"))\n",
    "\n",
    "proteins_annot = {record.id : \" \".join(record.description.split(\" \")[1:]) for record in SeqIO.parse(path_mill_db, \"fasta\") if record.id in dico_res}\n",
    "proteins_seq = {record.id : record.seq for record in SeqIO.parse(path_mill_db, \"fasta\") if record.id in dico_res}\n",
    "\n",
    "# Writting the fasta files :\n",
    "with open(f\"{path_proteins}/millard_depo.v3.fasta\", \"w\") as outfile :\n",
    "    for prot in tqdm(proteins_seq) :\n",
    "        outfile.write(f\">{prot} {proteins_annot[prot]}\\n{proteins_seq[prot]}\\n\")\n",
    "\n",
    "# Writting the results files :\n",
    "#for file in os.listdir(f\"{path_proteins}/DBsuite_depo\") :\n",
    "#    if file.split(\".\")[0] in proteins_annot :\n",
    "#        os.system(f\"cp {path_proteins}/DBsuite_depo/{file} {path_proteins}/millard_dbsuite_results/{file}\")\n",
    "            \n",
    "dico_annot = {}\n",
    "for prot in dico_res :\n",
    "    ipr = [ipr.split(\"__\")[0] for ipr in dico_res[prot]]\n",
    "    for index, ipr_entry in enumerate(ipr) :\n",
    "        if ipr_entry not in dico_annot :\n",
    "            ipr_annot = {proteins_annot[prot] : 1}\n",
    "            dico_annot[ipr_entry] = ipr_annot\n",
    "        elif proteins_annot[prot] not in dico_annot[ipr_entry]:\n",
    "            a = {proteins_annot[prot] : 1}\n",
    "            dico_annot[ipr_entry].update(a)\n",
    "        else :\n",
    "            dico_annot[ipr_entry][proteins_annot[prot]] += 1\n",
    "\n",
    "for ipr in dico_annot :\n",
    "    a = {\"total_count\" : dico_count[ipr]}\n",
    "    dico_annot[ipr].update(a)\n",
    "\n",
    "with open(f\"{path_proteins}/results_annotation.v3.json\", \"w\") as outfile:\n",
    "    json.dump(dico_annot, outfile) \n",
    "with open(f\"{path_proteins}/proteinID_annotation.v3.json\", \"w\") as outfile:\n",
    "    json.dump(proteins_annot, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=DBsuiste3__\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5 \n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=01-00:00:00 \n",
    "#SBATCH --output=DBsuiste3__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate bio_phylo\n",
    "\n",
    "python /home/conchae/ML_depolymerase/scripts/results_v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the sequence idex file :\n",
    "import os \n",
    "from Bio import SeqIO\n",
    "import pandas as pd \n",
    "\n",
    "path_millard = \"/home/conchae/ML_depolymerase/get_candidates/millard\"\n",
    "\n",
    "data = {}\n",
    "for rec in SeqIO.parse(f\"{path_millard}/millard_depo.v3.fasta\" , \"fasta\") :\n",
    "    if rec.seq not in data :\n",
    "        data[rec.seq] = [rec.id.split(\"__\")[0]]\n",
    "    else :\n",
    "        data[rec.seq].append(rec.id.split(\"__\")[0])\n",
    "        \n",
    "with open(f\"{path_millard}/df_sequences.index.v3.csv\" ,\"w\") as outfile :\n",
    "    for index_seq, seq in enumerate(list(data.keys())) :\n",
    "        for prot in data[seq] :\n",
    "            outfile.write(f\"{index_seq}\\t{prot}\\t{seq}\\n\")\n",
    "        \n",
    "df = pd.read_csv(f\"{path_millard}/df_sequences.index.v3.csv\", sep=\"\\t\", names = [\"index\",\"id\",\"sequence\"])       \n",
    "df = df.drop_duplicates(subset=[\"index\"], keep=\"first\")\n",
    "df.to_csv(f\"{path_millard}/df_sequences.index.clean.v3.csv\", sep=\"\\t\", columns = [\"index\",\"sequence\"], index=False)\n",
    "\n",
    "\n",
    "df_2 = pd.read_csv(f\"{path_millard}/df_sequences.index.clean.v2.csv\", sep=\"\\t\")\n",
    "with open(f\"{path_millard}/millard_depo.indexed.v3.fasta\" , \"w\") as outfile :\n",
    "    dico_interest = df.to_dict(\"records\")\n",
    "    for row in dico_interest :\n",
    "        outfile.write(f\">{row['index']}\\n{row['sequence']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "import time\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "path_trunc = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/Resdom/truncated_msa\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.csv\", sep=\"\\t\", header = 0)\n",
    "sequence_df = pd.read_csv(f\"{path_db}/Results_III_sequences.csv\", sep = \"\\t\" ,names= [\"index\", \"sequence\"])\n",
    "\n",
    "\n",
    "def f_path_tab(query) :\n",
    "    \"From the protein name, get the tab output with score >= 20\"\n",
    "    path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    path_tab = f\"{path_decipher}/{strain}/DBsuite_depo_v3/{prophage}/{query}.suite.tab\"\n",
    "    out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"consensus_start\",\"consensus_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "    df_tab = pd.read_csv(f\"{path_tab}\", sep=\"\\t\", names= out_names)\n",
    "    df_tab = df_tab[df_tab[\"score\"] >= 20]\n",
    "    sequence = open(f\"{path_decipher}/{strain}/tmp/{prophage}/{query}.fasta\").read().split(\"\\n\")[1]\n",
    "    return df_tab, sequence\n",
    "\n",
    "def get_qlimits(query,target) :\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    df_tab, sequence = f_path_tab(query)\n",
    "    #print(df_tab, target)\n",
    "    #return (1,2)\n",
    "    consensus_start = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_start\"].values[0] \n",
    "    consensus_stop = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_stop\"].values[0]\n",
    "    msa_seq = \"\".join(open(f\"{path_decipher}/{strain}/mmseqs_out/{prophage}/{query}.MSA.a2m\").read().split(\">\")[1].split(\"\\n\")[1:])\n",
    "    i = 0\n",
    "    for n in range(len(msa_seq)) :\n",
    "        if msa_seq[n] == \"-\" :\n",
    "            pass\n",
    "        else :\n",
    "            i += 1 \n",
    "        if n == int(consensus_start)-1 :\n",
    "            qstart = i\n",
    "        elif n == int(consensus_stop)-1 :\n",
    "            qstop = i \n",
    "            break            \n",
    "    return qstart, qstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "\n",
    "f_labels=[\"Prophage_name\",\"KL_ancestor\",\"Id_monophyletic_group\",\"Number of clades\",\"Number of leafs\",\"Number of new ancestors\",\"Number of k-type swap\",\"Nodes k-types\",\"Nodes k-types all\"]\n",
    "df_prophages = pd.read_csv(f\"{path_labels}/prophage_data.clusters_80.phageboost_70.tsv\", sep=\"\\t\", names =f_labels) \n",
    "\n",
    "results_DBsuite = json.load(open(f\"{path_db}/dbsuite_results.v3.json\"))\n",
    "\n",
    "def f_path_tab(query) :\n",
    "    \"From the protein name, get the tab output with score >= 20\"\n",
    "    path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    path_tab = f\"{path_decipher}/{strain}/DBsuite_depo_v3/{prophage}/{query}.suite.tab\"\n",
    "    out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"consensus_start\",\"consensus_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "    df_tab = pd.read_csv(f\"{path_tab}\", sep=\"\\t\", names= out_names)\n",
    "    df_tab = df_tab[df_tab[\"score\"] >= 20]\n",
    "    sequence = open(f\"{path_decipher}/{strain}/tmp/{prophage}/{query}.fasta\").read().split(\"\\n\")[1]\n",
    "    return df_tab, sequence\n",
    "\n",
    "def get_qlimits(query,target) :\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    df_tab, sequence = f_path_tab(query)\n",
    "    #print(df_tab, target)\n",
    "    #return (1,2)\n",
    "    consensus_start = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_start\"].values[0] \n",
    "    consensus_stop = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_stop\"].values[0]\n",
    "    msa_seq = \"\".join(open(f\"{path_decipher}/{strain}/mmseqs_out/{prophage}/{query}.MSA.a2m\").read().split(\">\")[1].split(\"\\n\")[1:])\n",
    "    i = 0\n",
    "    for n in range(len(msa_seq)) :\n",
    "        if msa_seq[n] == \"-\" :\n",
    "            pass\n",
    "        else :\n",
    "            i += 1 \n",
    "        if n == int(consensus_start)-1 :\n",
    "            qstart = i\n",
    "        elif n == int(consensus_stop)-1 :\n",
    "            qstop = i \n",
    "            break            \n",
    "    return qstart, qstop\n",
    "        \n",
    "# df 1 : [protein name, #sequence_index# , KL type ancestor, ancestor_id, IPR, score, qstart, qstop, sequence_aa]\n",
    "with open(f\"{path_db}/Results_III_DataFrame.v3.csv\", \"w\") as outfile :\n",
    "    for protein in tqdm(results_DBsuite) :\n",
    "        df_tab , sequence = f_path_tab(protein)\n",
    "        prophage = \"__\".join(protein.split(\"__\")[0:2])+\".fasta\"\n",
    "        df_prot = df_prophages[df_prophages[\"Prophage_name\"]==prophage]\n",
    "        kl_ancestor = df_prot[\"KL_ancestor\"].values[0]\n",
    "        ancestor_id = df_prot[\"Id_monophyletic_group\"].values[0]\n",
    "        #print(prophage, kl_ancestor , ancestor_id)\n",
    "        for index_tab, hit_ipr in df_tab.iterrows() :\n",
    "            target = hit_ipr[\"target\"]\n",
    "            start , stop = get_qlimits(protein,target)\n",
    "            score = hit_ipr[\"score\"]\n",
    "            if stop - start >= 30 :\n",
    "                outfile.write(f\"{protein}\\t{kl_ancestor}\\t{ancestor_id}\\t{target}\\t{score}\\t{start}\\t{stop}\\t{sequence}\\n\")\n",
    "                #print(f\"{protein}\\t{kl_ancestor}\\t{ancestor_id}\\t{target}\\t{score}\\t{start}\\t{stop}\\n\")         \n",
    "                \n",
    "                \n",
    "labels_results = [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\"]\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.csv\", sep=\"\\t\", names= labels_results)\n",
    "\n",
    "sequences_df = results_df[\"sequence\"].unique()\n",
    "with open(f\"{path_db}/Results_III_sequences.v3.csv\", \"w\") as outfile :\n",
    "    for index, sequence in enumerate(sequences_df) :\n",
    "        print(sequence)\n",
    "        outfile.write(f\"{index}\\t{sequence}\\n\")\n",
    "\n",
    "# *******************\n",
    "# DF with index sequences :\n",
    "\n",
    "import pandas as pd \n",
    "import os \n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "\n",
    "labels_results = [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\"]\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.csv\", sep=\"\\t\", names= labels_results)\n",
    "sequence_df = pd.read_csv(f\"{path_db}/Results_III_sequences.csv\", sep = \"\\t\" ,names= [\"index\", \"sequence\"])\n",
    "\n",
    "results_df[\"index_seq\"] = sequence_df[sequence_df[\"sequence\"]== results_df[\"sequence\"]][\"index\"]\n",
    "\n",
    "index_list = []\n",
    "for index , row in tqdm(results_df.iterrows()) :\n",
    "    index_list.append(sequence_df[sequence_df[\"sequence\"]== row[\"sequence\"]][\"index\"].values[0])\n",
    "    \n",
    "results_df[\"index_seq\"] = index_list\n",
    "results_df.to_csv(f\"{path_db}/Results_III_DataFrame.csv\", sep=\"\\t\",header =  [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\",\"index_seq\"], index = False )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
